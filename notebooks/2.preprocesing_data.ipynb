{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c79e55e-1a8c-454d-b14b-41056a41285d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from minio import Minio\n",
    "import urllib3\n",
    "\n",
    "# Conectar al servidor de MinIO\n",
    "client2 = Minio(\n",
    "    \"minio.minio-user.svc.cluster.local:80\",  # IP del servidor MinIO\n",
    "    access_key=\"0xJ9SgCXmkU3z704qgv1\",\n",
    "    secret_key=\"CgFth8x4tSU9BN9QWBSrMCncOycsWxiIC8egcBUx\",\n",
    "    secure=False,  # Cambia a True si usas HTTPS\n",
    "    http_client=urllib3.PoolManager(cert_reqs='CERT_NONE')  # Ignora la verificación del certificado\n",
    ")\n",
    "\n",
    "# Nombre del bucket y del archivo\n",
    "bucket_name = 'hudbayextraccion'\n",
    "object_name = 'bd_hubbay_pases_all.parquet'  # Nombre del archivo Parquet que quieres leer\n",
    "\n",
    "# Obtener el archivo Parquet del bucket\n",
    "response = client2.get_object(bucket_name, object_name)\n",
    "data = response.read()\n",
    "\n",
    "# Convertir los datos leídos en un DataFrame de Pandas\n",
    "parquet_buffer = BytesIO(data)\n",
    "datos = pd.read_parquet(parquet_buffer)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b3305de-ba91-459a-a90e-b8bb19fa6235",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "# 3.Tratamiento de valores Nulos\n",
    "# 3.1 Supongamos que tienes un DataFrame llamado datos\n",
    "valores_nulos = datos.isnull().sum()\n",
    "valores_nulos_ordenados = valores_nulos.sort_values(ascending=False)\n",
    "porcentaje_nulos = (valores_nulos_ordenados / len(datos)) * 100\n",
    "columnas_a_eliminar = porcentaje_nulos[porcentaje_nulos > 80].index\n",
    "datos = datos.drop(columnas_a_eliminar, axis=1)\n",
    "\n",
    "#4. Tratamiento de variables \n",
    "#4.1 Eliminando columnas especificas que no aportan informacion ( # errors='ignore':ignore cualquier error si alguna de las columnas especificadas no se encuentra en el DataFrame.)\n",
    "datos = datos.drop(['tipoubicacionsupervisor_camion','tipoubicacionsupervisor_pala', 'id_cargadescarga_pases','dumpreal','loadreal', 'rownum'], axis=1, errors='ignore') # 'turno'\n",
    "\n",
    "# 3.2 Calcula la moda de 'has_block_pases' y Completa los valores nulos con la moda en la columna 'has_block_pases'\n",
    "moda_has_block_pases = datos['has_block_pases'].mode()[0]\n",
    "datos['has_block_pases'].fillna(moda_has_block_pases, inplace=True)\n",
    "\n",
    "# 3.3 Calcula la moda de 'tipodescargaidentifier' y completa los valores nulos con la moda en la columna 'tipodescargaidentifier'\n",
    "moda_tipodescargaidentifier = datos['tipodescargaidentifier'].mode()[0]\n",
    "datos['tipodescargaidentifier'].fillna(moda_tipodescargaidentifier, inplace=True)\n",
    "\n",
    "#4. Transformacion de Datos Tiempo a formato Datetime\n",
    "#4.1 Convertir las columnas a DateTime si aun no la estan\n",
    "# Lista de columnas que contienen fechas\n",
    "columnas_fecha = ['tiem_llegada_global', 'tiem_esperando', 'tiem_cuadra', \n",
    "                  'tiem_cuadrado', 'tiem_carga', 'tiem_acarreo', 'tiem_cola', \n",
    "                  'tiem_retro', 'tiem_listo', 'tiem_descarga', 'tiem_viajando', \n",
    "                  'tiempo_inicio_carga_carguio', 'tiempo_esperando_carguio', \n",
    "                  'previous_esperando_pala', 'tiempo_inicio_cambio_estado_camion', \n",
    "                  'tiempo_inicio_cambio_estado_pala']\n",
    "\n",
    "# 4.2 Convertir todas las fechas al mismo formato y eliminar valores Nulos de los DATETIME\n",
    "for columna in columnas_fecha:\n",
    "    datos[columna] = pd.to_datetime(datos[columna], errors='coerce') #Si hubiese una fecha con  Error, lo reemplaza con NAT\n",
    "# 4.3 Reemplazar los valores nulos con la fecha de la fila anterior más 3 segundos adicionales\n",
    "for columna in columnas_fecha:\n",
    "    mask_nat = datos[columna].isna()\n",
    "    datos[columna].loc[mask_nat] = datos[columna].fillna(method='ffill') + pd.to_timedelta(3, unit='s')\n",
    "# 4.4 Formatear las fechas en el formato deseado\n",
    "formato_deseado = \"%Y-%m-%d %H:%M:%S.%f%z\"  # Formato deseado\n",
    "for columna in columnas_fecha:\n",
    "    datos[columna] = datos[columna].dt.strftime(formato_deseado)\n",
    "    datos[columna] = pd.to_datetime(datos[columna])\n",
    "    datos[columna] = datos[columna] + pd.to_timedelta(999, unit='ms')\n",
    "\n",
    "\n",
    "# 3.4 Rellenar los valores nulos con ceros en todo el DataFrame\n",
    "datos = datos.fillna(0)\n",
    "\n",
    "#5. Eliminamos los filas duplicadas\n",
    "# 5.1. Identificar las columnas no de tipo 'object'\n",
    "columnas_no_object = datos.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# 5.2. Eliminar duplicados basados solo en las columnas no 'object'\n",
    "datos = datos.drop_duplicates(subset=columnas_no_object)\n",
    "\n",
    "# 6. Transformacion a Tipo de datos adecuado formato para las variables\n",
    "# 6.1 Diccionario para especificar los tipos de datos deseados para cada columna\n",
    "tipos_de_datos = {\n",
    "    'id_ciclo_acarreo': 'int64','id_cargadescarga': 'int64','id_palas': 'int64','id_equipo_camion': 'int64','id_ciclo_carguio': 'float64',\n",
    "    'id_equipo_carguio': 'float64','id_trabajador_pala': 'float64','id_guardia_realiza_carga_al_camion': 'float64','id_locacion': 'float64',\n",
    "    'id_poligono_se_obtiene_material': 'float64','tiempo_ready_cargando_pala': 'float64','tiempo_ready_esperando_pala': 'float64',\n",
    "    'cantidad_equipos_espera_al_termino_carga_pala': 'float64','id_estados_camion': 'int64','id_equipo_table_estados_camion': 'int64',\n",
    "    'id_detal_estado_camion': 'int64','tiempo_estimado_duracion_estado_camion': 'int64','en_campo_o_taller_mantenimiento_camion': 'int64',\n",
    "    'id_tipo_estad_camion': 'int64','id_estados_pala': 'float64','id_equipo_table_estados_pala': 'float64','id_detal_estado_pala': 'float64',\n",
    "    'tiempo_estimado_duracion_estado_pala': 'float64','en_campo_o_taller_mantenimiento_pala': 'float64','id_tipo_estad_pala': 'float64',\n",
    "    'id_descarga': 'int64','id_factor': 'int64','id_poligono': 'float64', \n",
    "    #'tiempo_ready_llegada_esperando': 'float64','tiempo_ready_esperando_cuadra': 'float64','tiempo_ready_cuadra_cuadrado': 'float64', #'tiempo_ready_cuadrado_cargado': 'float64','tiempo_ready_carga_acarreo': 'float64','tiempo_ready_acarreo_cola': 'float64',#'tiempo_ready_cola_retro': 'float64','tiempo_ready_retro_listo': 'float64','tiempo_ready_listo_descarga': 'float64',#'tiempo_ready_descarga_viajandovacio': 'float64',\n",
    "    'id_trabajador_camion': 'int64','id_palanext': 'int64','tonelajevims': 'float64','yn_estado': 'bool',\n",
    "    'id_guardia_hizocarga': 'int64','id_guardia_hizodescarga': 'int64','id_zona_aplicafactor': 'int64','id_zona_pertenece_poligono': 'float64',\n",
    "    'factor': 'int64','toneladas_secas': 'float64',\n",
    "    #'productividad_operativa_acarreo_tn_h': 'float64',\n",
    "    'productividad_operativa_carguio_tn_h': 'float64','efhcargado': 'float64','efhvacio': 'float64','distrealcargado': 'float64','distrealvacio': 'float64','coorxdesc': 'float64',\n",
    "    'coorydesc': 'float64','coorzdesc': 'float64','tipodescargaidentifier': 'float64','tonelajevvanterior': 'int64','tonelajevvposterior': 'float64','velocidadvimscargado': 'float64','velocidadvimsvacio': 'float64','velocidadgpscargado': 'float64','velocidadgpsvacio': 'float64','tonelajevimsretain': 'float64', 'nivelcombuscargado': 'float64','nivelcombusdescargado':'float64',\n",
    "    'volumen': 'float64','aplicafactor_vol': 'bool','coorzniveldescarga': 'float64','efh_factor_loaded': 'float64','efh_factor_empty':'float64',\n",
    "    'id_secundario': 'int64','id_principal': 'int64','capacidad_vol_equipo': 'float64','capacidad_pes_equipo': 'float64',\n",
    "    'capacidadtanque_equipo': 'int64','peso_bruto_equipo': 'float64','ishp_equipo': 'bool','ancho_equipo': 'int64','largo_equipo': 'int64',\n",
    "    'numeroejes_equipo': 'int64','id_turnos_turnocarga': 'int64','horaini_turnocarga': 'int64','horafin_turnocarga': 'int64',\n",
    "    'id_turnos_turnodescarga': 'int64','horaini_turnodescarga': 'int64','horafin_turnodescarga': 'int64',\n",
    "    'id_zona_encuentra_descarga': 'int64','id_nodo_carga': 'float64','id_nodo_descarga': 'int64',\n",
    "    'elevacion_descarga': 'int64','nivel_elevacion_locacion_mts': 'float64','radio_locacion': 'float64','id_material': 'float64',\n",
    "    'elevacion_poligono_mts': 'float64','densidad_poligono': 'float64','tonelaje_inicial_poligono': 'float64','id_pases': 'float64',\n",
    "    'id_palas_pases': 'float64','angulo_giro_promedio_pases': 'float64','has_block_pases': 'bool','capacidad_pes_equipo_carguio': 'float64', 'capacidad_vol_equipo_carguio': 'float64', 'tonelaje': 'int64',\n",
    "    'radiohexagonocuchara_equipo_carguio': 'int64' }\n",
    "\n",
    "# 6.2 Convertir las columnas al tipo de dato correspondiente\n",
    "for columna, tipo in tipos_de_datos.items():\n",
    "    datos[columna] = datos[columna].astype(tipo)\n",
    "\n",
    "# 8. Transformacion de datos, convercion de Tipo de datos a Booleano (True/False)\n",
    "# VARIABLE 1 \n",
    "# 8.1 Reemplazar '0' por la moda\n",
    "datos['termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio'] = datos['termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio'].replace(0,  datos['termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio'].mode().iloc[0])\n",
    "# 8.2 Reemplazar 'True' por True y 'False' por False , Paso crucial para antes de Convertir a DATOS BOOLEANO\n",
    "datos['termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio'] = datos['termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio'].replace({'True': True, 'False': False})\n",
    "# 8.3 Convertir la columna a tipo de datos booleano\n",
    "datos['termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio'] = datos['termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio'].astype(bool)\n",
    "\n",
    "# VARIABLE 2\n",
    "# 8.4 Reemplazar '0' por la moda\n",
    "datos['cambio_estado_operatividad_carguio'] =datos['cambio_estado_operatividad_carguio'].replace(0, datos['cambio_estado_operatividad_carguio'].mode().iloc[0])\n",
    "\n",
    "# 8.5 Reemplazar 'True' por True y 'False' por False , Paso crucial para antes de Convertir a DATOS BOOLEANO\n",
    "datos['cambio_estado_operatividad_carguio'] = datos['cambio_estado_operatividad_carguio'].replace({'True': True, 'False': False})\n",
    "\n",
    "# 8.6 Convertir la columna a tipo de datos booleano\n",
    "datos['cambio_estado_operatividad_carguio'] = datos['cambio_estado_operatividad_carguio'].astype(bool)\n",
    "\n",
    "\n",
    "# #pasar tonelajevims a toneladas\n",
    "datos['tonelajevims'] = datos['tonelajevims'] / 10\n",
    "\n",
    "\n",
    "# 9. Renombrar variables para mayor entendimiento del negocio\n",
    "# Define un diccionario con los nuevos nombres de las columnas solo para algunas columnas\n",
    "nuevos_nombres = {'id_cargadescarga' : 'id_cargadescarga_ciclo',\n",
    "    'termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio' : 'al_termino_cargar_en_espera_cuadrado_cuadrandose',\n",
    "    'id_descarga' : 'id_zona_hace_descarga',  \n",
    "    'tiem_llegada_global': 'tiempo_llegada_camion', 'tiem_esperando': 'tiempo_esperando_camion_en_locacion', \n",
    "    'tiem_cuadra': 'tiempo_cuadra_camion','tiem_cuadrado': 'tiempo_cuadrado_camion' , 'tiem_carga' : 'tiempo_cargar_al_camion', \n",
    "    'tiem_acarreo' : 'tiempo_acarreo_camion', 'tiem_cola': 'tiempo_cola_camion_en_zonadescarga','tiem_retro': 'tiempo_retroceso_para_descargar',\n",
    "    'tiem_listo' : 'tiempo_listo_para_descargar',  'tiem_descarga': 'tiempo_descarga_camion', 'tiem_viajando': 'tiempo_viajando_vacio_locacion', \n",
    "    'tonelaje':'tonelaje_nominal', 'tonelajevims':'tonelaje_segun_computadora', 'yn_estado': 'cambios_estado_en_ciclo',\n",
    "    'distrealcargado': 'distancia_recorrida_camioncargado_km_gps_mts', 'distrealvacio': 'distancia_recorrida_camionvacio_km_gps_mts' ,\n",
    "    'coorxdesc': 'coordenada_x_descarga_km', 'coorydesc': 'coordenada_y_descarga_km' , 'coorzdesc': 'coordenada_z_descarga_km',\n",
    "    'tipodescargaidentifier': 'tipo_descarga_efectuado', \n",
    "    'tonelajevvanterior': 'tonelaje_camion_viajevacio_cicloanterior_vims', 'tonelajevvposterior': 'tonelaje_camion_viajevacio_cicloactual_vims',\n",
    "    'velocidadvimscargado': 'promedio_velocidad_camioncargado_km/hr_compu', \n",
    "    'velocidadvimsvacio': 'promedio_velocidad_camionvacio_km/hr_compu',\n",
    "    'velocidadgpscargado':'promedio_velocidad_camioncargado_km/hr_gps', 'velocidadgpsvacio': 'promedio_velocidad_camionvacio_km/hr_gps', \n",
    "    'tonelajevimsretain': 'tonelaje_camion_antes_cargaestabilizada', 'nivelcombuscargado': 'porcentaje_combustible_camioncargando', \n",
    "    'nivelcombusdescargado':'porcentaje_combustible_camiondescargando', 'volumen': 'volumen_nominal', 'aplicafactor_vol': 'aplica_factor_volumen_o_tonelaje',\n",
    "    'coorzniveldescarga': 'nivel_descarga_metros', 'nombre_equipo':'nombre_equipo_acarreo', \n",
    "    'id_secundario':'id_flota_secundaria', 'flota_secundaria':'nombre_flota_secundaria', 'id_principal': 'id_flota_principal', 'flota_principal':'nombre_flota_principal',\n",
    "    'capacidad_vol_equipo': 'capacidad_en_volumen_equipo_acarreo_m3', 'capacidad_pes_equipo':'capacidad_en_peso_equipo_acarreo', 'capacidadtanque_equipo': 'capacidadtanque_equipoacarreo_galones',\n",
    "    'peso_bruto_equipo':'peso_bruto_equipo_acarreo', 'ishp_equipo':'si_no_equipo_altaprecision', 'ancho_equipo':'ancho_equipo_metros', 'largo_equipo':'largo_equipo_metros',\n",
    "    'elevacion_descarga':'nivel_elevacion_descarga_metros', 'nombre_descarga':'nombre_zona_descarga', \n",
    "    'nombre_carga_locacion':'nombre_locacion_carga', 'nivel_elevacion_locacion_mts':'nivel_elevacion_locacion_carga_metros', 'radio_locacion':'radio_locacion_metros',\n",
    "    'ids_poligonos_en_locacion':'ids_poligonos_en_locacion_carga', 'id_material': 'id_material_dominante_en_poligono', \n",
    "    'elevacion_poligono_mts':'elevacion_poligono_metros', 'ley_in':'lista_leyes', 'densidad_poligono':'densidad_inicial_poligono_creado_tn/m3',\n",
    "    'capacidad_vol_equipo_carguio' : 'capacidad_en_volumen_equipo_carguio_m3', 'capacidad_pes_equipo_carguio':'capacidad_en_peso_equipo_carguio', 'capacidadtanque_equipo_carguio': 'capacidadtanque_equipocarguio_galones',\n",
    "    'radiohexagonocuchara_equipo_carguio' : 'radiohexagonocuchara_equipocarguio', 'id_tablegen' : 'id_guardia_acarreocarga', 'nombre_tablegen' : 'nombre_guardia_acarreocarga', \n",
    "    'id_guardiadescarga': 'id_guardia_acarreodescarga', 'nombre_guardiadescarga':'nombre_guardia_acarreodescarga',\n",
    "    'id':'id_guardia_carguio', 'nombre': 'nombre_guardia_carguio', 'id_locacion' : 'id_locacion_hace_carga','tonelaje_inicial_poligono': 'tonelaje_inicial_poligono_creado',  'efhvacio':'efhvacio_mts', 'efhcargado':'efhcargado_mts'\n",
    "}\n",
    "# 9.1 Renombra las columnas del DataFrame\n",
    "datos = datos.rename(columns=nuevos_nombres)\n",
    "\n",
    "#10. Agregamos Nuevas variables calculadas\n",
    "#Agregamos la variable 'porcentaje_eficiencia_toneladas_movidas_acarreo'\n",
    "datos['porcentaje_eficiencia_toneladas_movidas_acarreo'] = (datos['tonelaje_segun_computadora'] / datos['tonelaje_nominal']) * 100\n",
    "\n",
    "#Agregamos la variable 'altura_elevacion'\n",
    "datos['altura_elevacion'] = abs(datos['nivel_elevacion_descarga_metros'] - datos['nivel_elevacion_locacion_carga_metros'] )\n",
    "\n",
    "# Agregamos la variable 'factor_perfil_rutavacio_mts'\n",
    "datos['factor_perfil_rutavacio'] = np.where(datos['distancia_recorrida_camionvacio_km_gps_mts'] != 0,\n",
    "                                            datos['efhvacio_mts'] / datos['distancia_recorrida_camionvacio_km_gps_mts'],\n",
    "                                            0)\n",
    "\n",
    "# Agregamos la variable 'factor_perfil_rutacargado_mts'\n",
    "datos['factor_perfil_rutacargado'] = np.where(datos['distancia_recorrida_camioncargado_km_gps_mts'] != 0,\n",
    "                                              datos['efhcargado_mts'] / datos['distancia_recorrida_camioncargado_km_gps_mts'],\n",
    "                                              0)\n",
    "\n",
    "# Agregamos la variable calculada \"numero_pases_carguio\" basado en la columna 'coord_x_pases'\n",
    "# datos['numero_pases_carguio'] = datos['coord_x_pases'].apply(lambda x: len(eval(x)) if isinstance(x, str) and '[' in x else x if isinstance(x, int) else 0)\n",
    "# Calcular el número de elementos en cada array y manejar arrays vacíos\n",
    "datos['numero_pases_carguio'] = datos['coord_x_pases'].apply(lambda x: len(x) if isinstance(x, np.ndarray) else 0)\n",
    "\n",
    "#Agregamos la variable Galones_diponible_camioncargando\n",
    "datos['Galones_disponibles_camioncargando'] = (datos['porcentaje_combustible_camioncargando']/100) * datos['capacidadtanque_equipoacarreo_galones']\n",
    "#datos['demanda_galones_camioncargando'] = (datos['porcentaje_combustible_camioncargando']/100) * datos['capacidadtanque_equipoacarreo_galones']\n",
    "\n",
    "#Agregar la variable Galones_diponible_camiondescargando \n",
    "datos['Galones_disponibles_camiondescargando'] = (datos['porcentaje_combustible_camiondescargando']/100) * datos['capacidadtanque_equipoacarreo_galones']\n",
    "\n",
    "#Agregar la variable Galones_consumidos_entre_cargando_descargando \n",
    "datos['Galones_consumidos_entre_cargando_descargando_acarreo'] = datos['Galones_disponibles_camioncargando'] - datos['Galones_disponibles_camiondescargando']\n",
    "\n",
    "\n",
    "# 11. Agregar mas filtros \n",
    "#11.1 Filtramos la fecha\n",
    "fecha_minima = '2023-01-01 00:00:00.999'\n",
    "datos=datos.sort_values(by='tiempo_inicio_carga_carguio') \n",
    "datos=datos[datos['tiempo_inicio_carga_carguio'] > fecha_minima]\n",
    "\n",
    "# 12. Calculo tonelaje por pase\n",
    "# Paso 1: Asegúrate de que todos los datos en 'tonelaje_pases' son cadenas de texto\n",
    "datos['tonelaje_pases'] = datos['tonelaje_pases'].astype(str)\n",
    "\n",
    "# Paso 2: Reemplazar espacios por comas en las cadenas de texto\n",
    "datos['tonelaje_pases'] = datos['tonelaje_pases'].apply(lambda x: x.replace(' ', ','))\n",
    "\n",
    "# Paso 3: Reemplazar cualquier carácter no numérico (excepto comas) por vacío\n",
    "datos['tonelaje_pases'] = datos['tonelaje_pases'].str.replace(r'[^\\d,]', '', regex=True)\n",
    "\n",
    "# Paso 4: Dividir las cadenas en columnas usando comas como delimitador\n",
    "tabla_datos2 = datos['tonelaje_pases'].str.split(',', expand=True)\n",
    "\n",
    "# Paso 5: Reemplazar valores vacíos por NaN y luego convertir a float\n",
    "tabla_datos2 = tabla_datos2.replace('', np.nan).astype(float)\n",
    "\n",
    "# Paso 6: Calcular la suma de los tonelajes por fila y dividir por 10\n",
    "datos['tonelaje_pases'] = tabla_datos2.sum(axis=1) / 10\n",
    "\n",
    "# Filtro \n",
    "# 13. Tratamiento de Valores Outliers (Numero de Pases)\n",
    "mask = datos['numero_pases_carguio'] >= 4\n",
    "datos = datos[mask]\n",
    "\n",
    "# 13. Reeemplzar Capacidad carguio != 0 (Numero de Pases)\n",
    "mask = datos['capacidad_en_peso_equipo_carguio']  != 0 \n",
    "datos = datos[mask]\n",
    " \n",
    "# Filtramos los tonelajes Vims (70% * capacidad de tolva) , para tener ciclos con pases \n",
    "mask = (datos['tonelaje_segun_computadora'] > 150)\n",
    "datos = datos[mask]\n",
    " \n",
    "# Filtramos los tonelajes por pases, que sean distintos de 0, en cada pase que se dio \n",
    "mask = datos['tonelaje_pases'] > 0\n",
    "datos = datos[mask]\n",
    " \n",
    "# Filtrar las tonaledas por pase. que los pases dados, sean superioes a (70%capacidad tolva) y menores al (125%capacidad tolva)\n",
    "mask = (datos['tonelaje_pases'] >= 180) & (datos['tonelaje_pases'] <= 400)\n",
    "datos = datos[mask]\n",
    " \n",
    "# # Filtramos la Procedencia de Material diferente de DES \n",
    "# mask = datos['Procedencia'] != 'DES'\n",
    "# datos = datos[mask]\n",
    " \n",
    "# Filtramos solo pases por encima de 4, y los configuramos con el tonelaje Vims \n",
    "mask = datos['numero_pases_carguio'] >= 4\n",
    "datos.loc[mask, 'numero_pases_carguio2'] = (datos[mask]['tonelaje_segun_computadora'] / datos[mask]['capacidad_en_peso_equipo_carguio']).round(0)\n",
    "\n",
    "\n",
    "# Paso 1: Cambiar 'DELAY' a 'READY' donde el estado no es 'DELAY' y 'numero_pases_carguio' es diferente de 0\n",
    "datos.loc[(datos['estado_primario_pala'] != 'DELAY'), 'estado_primario_pala'] = 'READY'\n",
    "\n",
    "# Paso 2: Cambiar 'DELAY' a 'READY' donde 'numero_pases_carguio' es diferente de 0\n",
    "datos.loc[(datos['estado_primario_pala'] == 'DELAY') & (datos['numero_pases_carguio'] > 0), 'estado_primario_pala'] = 'READY'\n",
    "\n",
    "# Paso 3: Filtrar solo los estados 'READY' (donde se efectuaron pases)\n",
    "datos = datos[(datos['estado_primario_pala'] == 'READY') & (datos['numero_pases_carguio'] > 0)]\n",
    "\n",
    "# Agregamos la variable 'tiempo de carga', cuanto demora el operador de carguio en realizar el carguio al camion de acarreo\n",
    "datos['tiempo_carga'] = (datos['tiempo_esperando_carguio'] - datos['tiempo_inicio_carga_carguio']).dt.total_seconds() #Pasas a segundos\n",
    "\n",
    "\n",
    "#4.1 Eliminando columnas especificas que no aportan informacion\n",
    "datos = datos.drop(['previous_esperando_pala','ids_poligonos_en_locacion_carga', 'estado_detalle_camion', 'estado_secundario_camion', 'estado_primario_camion', 'estado_detalle_pala',\n",
    "       'estado_secundario_pala', 'estado_primario_pala','nombre_equipo_acarreo', 'nombre_flota_secundaria','nombre_flota_principal', 'nombre_turnocarga',\n",
    "       'nombre_turnodescarga', 'nombre_zona_descarga', 'nombre_locacion_carga', 'nombre_poligono', 'lista_leyes', 'coord_x_pases', 'coord_y_pases', 'coord_z_pases', \n",
    "        'angulo_giro_pases', 'duracion_excavacion_pases'], axis=1, errors='ignore') # errors='ignore':ignore cualquier error si alguna de las columnas especificadas no se encuentra en el DataFrame.\n",
    "\n",
    "# Remover la zona horaria de las columnas datetime\n",
    "for col in ['tiempo_inicio_carga_carguio', 'tiempo_esperando_carguio', 'tiempo_inicio_cambio_estado_camion', \n",
    "            'tiempo_inicio_cambio_estado_pala', 'tiempo_llegada_camion', 'tiempo_esperando_camion_en_locacion',\n",
    "            'tiempo_cuadra_camion', 'tiempo_cuadrado_camion', 'tiempo_cargar_al_camion', 'tiempo_acarreo_camion',\n",
    "            'tiempo_cola_camion_en_zonadescarga', 'tiempo_retroceso_para_descargar', 'tiempo_listo_para_descargar',\n",
    "            'tiempo_descarga_camion', 'tiempo_viajando_vacio_locacion']:\n",
    "    if pd.api.types.is_datetime64tz_dtype(datos[col]):\n",
    "        datos[col] = datos[col].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2840e496-393a-4e9e-948f-7ac7ebb596a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68259ab5-6ace-487b-96da-83b5fe8fd269",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from minio import Minio\n",
    "\n",
    "# client = Minio(\n",
    "#     \"minio.minio-user.svc.cluster.local:80\",\n",
    "#     access_key=\"0xJ9SgCXmkU3z704qgv1\",\n",
    "#     secret_key=\"CgFth8x4tSU9BN9QWBSrMCncOycsWxiIC8egcBUx\",\n",
    "#     secure=False\n",
    "# )\n",
    "\n",
    "# buckets = client.list_buckets()\n",
    "# for bucket in buckets:\n",
    "#     print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6b0afe6-b333-4955-a256-d9e65923533d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificar que los JARs se hayan agregado\n",
    "# print(spark.sparkContext.getConf().get(\"spark.jars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92b50c49-2b19-4726-8074-b6c36fb29d10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "import pandas as pd\n",
    "\n",
    "#!pip install delta-spark\n",
    "S3_ACCESS_KEY = \"M43n0lUIUeUNtfTC8JDV\"\n",
    "S3_BUCKET = \"hudbaypreprocesingdata\"\n",
    "S3_SECRET_KEY = \"JWxerXisx33WhSFvRkUfDSBManAPNsPOukTOKTEd\"\n",
    "S3_ENDPOINT = \"minio.minio-user.svc.cluster.local:80\"\n",
    "\n",
    "hadoop_common_jar = \"/home/jovyan/jars/hadoop-client-api-3.3.4.jar,/home/jovyan/jars/hadoop-client-runtime-3.3.4.jar,/home/jovyan/jars/hadoop-common-3.3.4.jar\"\n",
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName(\"AppDeltaMinio9\") \\\n",
    "  .config(\"spark.executor.memory\", \"8g\") \\\n",
    "  .config(\"spark.executor.cores\", \"2\") \\\n",
    "  .config(\"spark.driver.memory\", \"4g\") \\\n",
    "  .config(\"spark.driver.cores\", \"2\") \\\n",
    "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "  .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:3.3.4,io.delta:delta-spark_2.12:3.2.0,com.amazonaws:aws-java-sdk-pom:1.12.720\") \\\n",
    "  .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "  .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "  .config(\"spark.hadoop.fs.s3a.endpoint\", S3_ENDPOINT) \\\n",
    "  .config(\"spark.hadoop.fs.s3a.access.key\", S3_ACCESS_KEY) \\\n",
    "  .config(\"spark.hadoop.fs.s3a.secret.key\", S3_SECRET_KEY) \\\n",
    "  .config(\"spark.jars\", hadoop_common_jar) \\\n",
    "  .getOrCreate()\n",
    "\n",
    "# Supongamos que tienes un DataFrame de pandas llamado 'datos'\n",
    "spark_df = spark.createDataFrame(datos)\n",
    "#spark_df2 = spark.createDataFrame(datos).repartition(30)\n",
    "\n",
    "spark_df.write.format(\"delta\").save(\"s3a://hudbaypreprocesingdata/tabladelta_preprocesing_hudbay_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49cc239f-ca6c-4bb3-acc1-af6f6d54364a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Leer la tabla Delta desde MinIO\n",
    "delta_df = spark.read.format(\"delta\").load(\"s3a://hudbaypreprocesingdata/tabladelta_preprocesing_hudbay_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "618c6f1f-3bdc-4346-9f74-47cbcbdc48c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos = delta_df.toPandas()\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de61d424-a16f-48f1-bbc7-6cb5fa820621",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "2.preprocesing_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
