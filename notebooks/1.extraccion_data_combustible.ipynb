{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b6f9353-8c8e-4edd-9ea2-958b76be10a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97c42aff-a658-4300-b12c-e95a9aa12fc8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Extraccion de datos de BD Postgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c760d3d-22d4-46f6-a0d6-d45c335c0116",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def consultar_postgres_hudbay():\n",
    "    host = \"192.168.5.114\"\n",
    "    database = \"ControlSenseDB\"\n",
    "    user = \"postgres\"\n",
    "    password = \"larc0mar\"\n",
    "    # Establecer la conexión a la base de datos\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            host=host,\n",
    "            database=database,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "\n",
    "        # Crear un cursor para ejecutar comandos SQL\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Establecer la zona horaria antes de ejecutar la consulta\n",
    "        time_zone_query = \"SET TIME ZONE 'America/Lima';\"\n",
    "        cursor.execute(time_zone_query)\n",
    "\n",
    "        # Tu consulta SQL con el parámetro parametro\n",
    "        tu_query_sql = ''' \n",
    "        select z.* from (select distinct a.id id_ciclo_acarreo, a.id_cargadescarga, a.id_palas, a.id_equipo id_equipo_camion,  \n",
    "        m.id_ciclo_carguio,\tm.id_equipo_carguio , m.id_trabajador id_trabajador_pala, m.id_crew id_guardia_realiza_carga_al_camion,\n",
    "        m.id_locacion id_locacion, \n",
    "        m.id_poligono id_poligono_se_obtiene_material, m.tiempo_inicio_carga_carguio, m.tiempo_esperando_carguio, \n",
    "        m.tiempo_ready_cargando tiempo_ready_cargando_pala, m.tiempo_ready_esperando tiempo_ready_esperando_pala,\n",
    "        m.previous_esperando_pala, m.isspot termino_carga_equipo_en_espera_cuadrado_cuadrandose_carguio, m.bool_estado cambio_estado_operatividad_carguio,\n",
    "        m.bool_equipo_next tiene_camion_cuadrado_al_termino_carga_pala, m.cola cantidad_equipos_espera_al_termino_carga_pala,\n",
    "        s.id_estados id_estados_camion, s.id_equipo id_equipo_table_estados_camion, s.id_detal_estado id_detal_estado_camion, s.tiempo_inicio_cambio_estado tiempo_inicio_cambio_estado_camion,\n",
    "        s.tiempo_estimado_duracion_estado tiempo_estimado_duracion_estado_camion,\n",
    "        s.en_campo_o_taller_mantenimiento en_campo_o_taller_mantenimiento_camion, s.tipoubicacionsupervisor tipoubicacionsupervisor_camion,\n",
    "        s.id_tipo_estad id_tipo_estad_camion, s.estado_detalle estado_detalle_camion, s.estado_secundario estado_secundario_camion, \t\t\t\t \n",
    "        s.estado_primario estado_primario_camion,\n",
    "        ss.id_estados id_estados_pala, ss.id_equipo id_equipo_table_estados_pala, ss.id_detal_estado id_detal_estado_pala, \n",
    "        ss.tiempo_inicio_cambio_estado tiempo_inicio_cambio_estado_pala, ss.tiempo_estimado_duracion_estado tiempo_estimado_duracion_estado_pala,\n",
    "        ss.en_campo_o_taller_mantenimiento en_campo_o_taller_mantenimiento_pala, ss.tipoubicacionsupervisor tipoubicacionsupervisor_pala, \n",
    "        ss.id_tipo_estad id_tipo_estad_pala, ss.estado_detalle estado_detalle_pala, ss.estado_secundario estado_secundario_pala, \t\t\t\t \n",
    "        ss.estado_primario estado_primario_pala,\n",
    "        a.id_descarga, a.id_factor, m.id_poligono, a.tiem_llegada tiem_llegada_global, a.tiem_esperando, a.tiem_cuadra, a.tiem_cuadrado,\n",
    "        a.tiem_carga, a.tiem_acarreo, a.tiem_cola, a.tiem_retro, a.tiem_listo,a.tiem_descarga, a.tiem_viajando,\n",
    "        a.id_trabajador id_trabajador_camion, a.id_palanext, a.tonelaje, a.tonelajevims, \n",
    "        a.id_mezcla, a.yn_estado, a.yn_operador, a.id_crewcarga id_guardia_hizocarga, a.id_crewdescarga id_guardia_hizodescarga,  \n",
    "        b.id_zona id_zona_aplicafactor, o.id_zona id_zona_pertenece_poligono, b.factor,\n",
    "        (a.tonelajevims/10) * (b.factor/1000) toneladas_secas,\n",
    "        (a.tonelajevims / 10.0) / NULLIF(((m.tiempo_ready_cargando + m.tiempo_ready_esperando) / 3600), 0)  productividad_operativa_carguio_tn_h,\t\t\t \t\t \n",
    "        a.efhcargado, a.efhvacio, a.distrealcargado, a.distrealvacio, a.coorxdesc, a.coorydesc, a.coorzdesc, \n",
    "        a.tipodescargaidentifier, a.tonelajevvanterior, a.tonelajevvposterior, a.dumpreal, a.loadreal, a.velocidadvimscargado,\n",
    "        a.velocidadvimsvacio, a.velocidadgpscargado, a.velocidadgpsvacio, a.tonelajevimsretain, a.nivelcombuscargado, a.nivelcombusdescargado,\n",
    "        a.volumen, a.aplicafactor_vol, a.coorzniveldescarga,\n",
    "        a.efh_factor_loaded, a.efh_factor_empty,f.nombre_equipo, f.id_secundario, f.secundario flota_secundaria, f.id_principal, f.principal flota_principal,\n",
    "        f.capacidad_vol capacidad_vol_equipo, f.capacidad_pes capacidad_pes_equipo, f.capacidadtanque capacidadtanque_equipo, \n",
    "        f.fcorrec_efhod fcorrec_efhod_equipo, f.fcorrec_efhdo fcorrec_efhdo_equipo, f.pesobruto peso_bruto_equipo, f.ishp ishp_equipo,\n",
    "        f.ancho ancho_equipo, f.largo largo_equipo, f.numeroejes numeroejes_equipo, f.tipoespecial tipoespecial_equipo, \n",
    "        f.radiohexagonoequipo radiohexagonoequipo_equipo, f.radiohexagonocuchara radiohexagonocuchara_equipo, \n",
    "        ff.nombre_equipo nombre_equipo_carguio,\n",
    "        ff.capacidad_vol capacidad_vol_equipo_carguio, ff.capacidad_pes capacidad_pes_equipo_carguio, ff.capacidadtanque capacidadtanque_equipo_carguio, \n",
    "        ff.radiohexagonoequipo radiohexagonoequipo_carguio, ff.radiohexagonocuchara radiohexagonocuchara_equipo_carguio, \n",
    "        g.id_turnos id_turnos_turnocarga, g.nombre nombre_turnocarga, g.horaini horaini_turnocarga, g.horafin horafin_turnocarga,\n",
    "        h.id_turnos id_turnos_turnodescarga, h.nombre nombre_turnodescarga, h.horaini horaini_turnodescarga, h.horafin horafin_turnodescarga,\n",
    "        j.id_tajo id_zona_encuentra_descarga, n.id_nodo id_nodo_carga, p.nombre_nodo nombre_nodo_carga, p.idzona id_zona_nodo_carga,\n",
    "        j.id_nodo id_nodo_descarga, q.nombre_nodo nombre_nodo_descarga, q.idzona id_zona_nodo_descarga, j.nivel elevacion_descarga, \n",
    "        j.nombre nombre_descarga, n.nombre nombre_carga_locacion, n.nivel nivel_elevacion_locacion_mts, n.radio radio_locacion, \n",
    "        n.poligono_ids ids_poligonos_en_locacion, o.id_material, o.nombre nombre_poligono, o.nivel elevacion_poligono_mts, o.ley_in, \n",
    "        o.densidad densidad_poligono, o.tonelaje_inicial tonelaje_inicial_poligono,\n",
    "        t.id id_pases, \tt.id_palas id_palas_pases, \tt.id_cargadescarga id_cargadescarga_pases, t.coord_x \tcoord_x_pases,\n",
    "        t.coord_y coord_y_pases, t.coord_z coord_z_pases, t.angulo_giro angulo_giro_pases, t.tonelaje tonelaje_pases, \n",
    "        t.duracion_excavacion duracion_excavacion_pases, t.angulo_giro_promedio angulo_giro_promedio_pases, t.has_block has_block_pases,\n",
    "        ROW_NUMBER() OVER (PARTITION BY a.id ORDER BY a.id DESC) AS RowNum\n",
    "        from public.tp_cargadescarga a\n",
    "        left join public.ta_factortonelaje b\n",
    "        on a.id_factor = b.id\n",
    "        left join (select d.id_principal, d.principal, d.id_secundario, d.secundario, c.id id_equipo, c.nombre nombre_equipo, c.capacidad_vol,\n",
    "        c.capacidad_pes, c.capacidadtanque, c.fcorrec_efhod, c.fcorrec_efhdo, c.pesobruto, c.ishp, c.ancho, c.largo,\n",
    "        c.numeroejes, c.anho, c.tipoespecial, c.radiohexagonoequipo, c.radiohexagonocuchara\n",
    "        from public.ts_equipos c\n",
    "        inner join (select b.id id_principal , b.nombre principal, a.id id_secundario , a.nombre secundario from public.ts_equipos a\n",
    "        inner join (select id, nombre from public.ts_equipos where id_flota = 0 and tiem_elimin is null) b\n",
    "        on b.id = a.id_flota\n",
    "        where a.tiem_elimin is null) d\n",
    "        on d.id_secundario = c.id_flota\n",
    "        where c.id_flota <> 0 and c.isflota = false and c.tiem_elimin is null\n",
    "        order by d.id_principal) f\n",
    "        on a.id_equipo = f.id_equipo\n",
    "        left join (select id, id_turnos, nombre, horaini, horafin from public.ts_turnos\n",
    "        where tiem_elimin is null) g\n",
    "        on a.id_turnocarga = g.id\n",
    "        left join (select id, id_turnos, nombre, horaini, horafin from public.ts_turnos\n",
    "        where tiem_elimin is null) h\n",
    "        on a.id_turnodescarga = h.id\n",
    "        left join public.ts_descarga j \n",
    "        on a.id_descarga = j.id\n",
    "        left join (\n",
    "        SELECT tp.id id_ciclo_carguio, tp.id_palas, tp.id_equipo as id_equipo_carguio, \n",
    "        tp.id_locacion, \n",
    "        tp.id_poligono, tp.id_trabajador, tp.id_crew, tp.isspot, tp.bool_estado, tp.bool_equipo_next, tp.cola, \n",
    "        tcd1.tiem_carga as tiempo_inicio_carga_carguio,\n",
    "        tcd1.tiem_acarreo as tiempo_esperando_carguio,\n",
    "        getreadytime( tp.id_equipo, tcd1.tiem_carga, tcd1.tiem_acarreo) tiempo_ready_cargando,\n",
    "        getreadytime( tp.id_equipo, \n",
    "                    lag(tcd1.tiem_acarreo) OVER (PARTITION BY (COALESCE(null, true)), tp.id_equipo ORDER BY tcd1.tiem_carga), \n",
    "                    tcd1.tiem_carga) tiempo_ready_esperando,\n",
    "        lag(tcd1.tiem_acarreo) OVER (PARTITION BY (COALESCE(null, true)), tp.id_equipo ORDER BY tcd1.tiem_carga) AS previous_esperando_pala,\n",
    "        tcd1.tiem_acarreo,\n",
    "        tcd1.tiem_carga\n",
    "        --tcd1.*\n",
    "        FROM tp_cargadescarga tcd1\n",
    "        LEFT JOIN tp_palas tp ON tp.id = (SELECT id \n",
    "                                FROM tp_palas \n",
    "                                    WHERE id_palas = tcd1.id_palas\n",
    "                                    ORDER BY ID DESC LIMIT 1)\n",
    "        WHERE tcd1.tiem_elimin IS NULL\n",
    "        AND tcd1.tiem_viajando IS NOT NULL\n",
    "        and tp.tiem_elimin IS NULL and tcd1.tiem_carga > '2023-09-27 00:00:00' and tcd1.tiem_carga < '2023-12-27 00:00:00') m   --MODIFICAR FECHAS (1 mes atras, etc) CURRENT_TIMESTAMP - INTERVAL '1 year'\n",
    "        on a.id_palas = m.id_palas\n",
    "        left join public.ts_locacion n\n",
    "        on m.id_locacion = n.id\n",
    "        left join public.ts_poligono o\n",
    "        on m.id_poligono = o.id\n",
    "        left join (select * from public.tp_nodos\n",
    "        where loc_carga = 'true' and tiem_elimin is null) p\n",
    "        on n.id_nodo = p.id --id_nodo\n",
    "        left join (select * from public.tp_nodos\n",
    "        where loc_descarga = 'true' and tiem_elimin is null) q\n",
    "        on j.id_nodo = q.id\t\t\t\t \n",
    "        left join (select d.id_principal, d.principal, d.id_secundario, d.secundario, c.id id_equipo, c.nombre nombre_equipo, c.capacidad_vol,\n",
    "        c.capacidad_pes, c.capacidadtanque, c.fcorrec_efhod, c.fcorrec_efhdo, c.pesobruto, c.ishp, c.ancho, c.largo,\n",
    "        c.numeroejes, c.anho, c.tipoespecial, c.radiohexagonoequipo, c.radiohexagonocuchara\n",
    "        from public.ts_equipos c\n",
    "        inner join (select b.id id_principal , b.nombre principal, a.id id_secundario , a.nombre secundario from public.ts_equipos a\n",
    "        inner join (select id, nombre from public.ts_equipos where id_flota = 0 and tiem_elimin is null) b\n",
    "        on b.id = a.id_flota\n",
    "        where a.tiem_elimin is null) d\n",
    "        on d.id_secundario = c.id_flota\n",
    "        where c.id_flota <> 0 and c.isflota = false and c.tiem_elimin is null\n",
    "        order by d.id_principal) ff\n",
    "        on m.id_equipo_carguio = ff.id_equipo\t\t \n",
    "        left join (select z.* from\n",
    "        (select A.id, A.id_estados, A.id_equipo, A.id_detal_estado, A.tiempo_inicio tiempo_inicio_cambio_estado,\n",
    "        A.tiempo_estimado tiempo_estimado_duracion_estado, A.idenestado en_campo_o_taller_mantenimiento,\n",
    "        A.tipoubicacionsupervisor,\n",
    "        B.id_tipo_estad, B.nombre as estado_detalle,\n",
    "        (select nombre from public.ts_detal_estado where id=B.id_tipo_estad limit 1) as estado_secundario, \n",
    "        (select nombre from public.ts_detal_estado where id = (select id_tipo_estad from public.ts_detal_estado where id=B.id_tipo_estad limit 1) limit 1) as estado_primario,\n",
    "        ROW_NUMBER() OVER (PARTITION BY A.id_equipo ORDER BY A.id_equipo) AS row_num\n",
    "        from public.tp_estados A\n",
    "        left join public.ts_detal_estado B on A.id_detal_estado = B.id_detal_estado\n",
    "        --left join (select * from public.ts_detal_estado where id=B.id_tipo_estad limit 1) C on true\n",
    "        where A.tiem_elimin is null) z\n",
    "        WHERE\n",
    "        z.row_num = 1) s\n",
    "        on a.id_equipo = s.id_equipo\n",
    "        left join (select z.* from\n",
    "            (select A.id, A.id_estados, A.id_equipo, A.id_detal_estado, A.tiempo_inicio tiempo_inicio_cambio_estado,\n",
    "            A.tiempo_estimado tiempo_estimado_duracion_estado, A.idenestado en_campo_o_taller_mantenimiento,\n",
    "            A.tipoubicacionsupervisor,\n",
    "            B.id_tipo_estad, B.nombre as estado_detalle,\n",
    "            (select nombre from public.ts_detal_estado where id=B.id_tipo_estad limit 1) as estado_secundario, \n",
    "            (select nombre from public.ts_detal_estado where id = (select id_tipo_estad from public.ts_detal_estado where id=B.id_tipo_estad limit 1) limit 1) as estado_primario,\n",
    "            ROW_NUMBER() OVER (PARTITION BY A.id_equipo ORDER BY A.id_equipo) AS row_num\n",
    "            from public.tp_estados A\n",
    "            left join public.ts_detal_estado B on A.id_detal_estado = B.id_detal_estado\n",
    "            --left join (select * from public.ts_detal_estado where id=B.id_tipo_estad limit 1) C on true\n",
    "            where A.tiem_elimin is null) z\n",
    "            WHERE\n",
    "            z.row_num = 1) ss\n",
    "        on m.id_equipo_carguio = ss.id_equipo\n",
    "        left join (select * from public.ta_datacarga_sensores \n",
    "        where tiem_elimin is NULL) t\n",
    "        on a.id_cargadescarga = t.id_cargadescarga\n",
    "        left join (select * from public.ta_guardias) w\n",
    "        on a.id_crewcarga = w.id\n",
    "        left join (select * from public.ta_guardias) x\n",
    "        on a.id_crewdescarga = x.id\n",
    "        left join (select * from public.ta_guardias) y\n",
    "        on m.id_crew = y.id\n",
    "        where a.tiem_elimin is null and a.tiem_llegada > '2023-09-27 00:00:00' and a.tiem_llegada < '2023-12-27 00:00:00' and b.factor is not null ) z --and g.id_turnos= 1 and h.id_turnos = 1, --MODIFICAR FECHAS (1 mes atras, etc))\n",
    "        -- CURRENT_TIMESTAMP - INTERVAL '1 year' 2015-12-01 09:45:21 y 2024-06-27 13:52:12.488+00\n",
    "        -- year, month, etc\n",
    "        where z.RowNum = 1\n",
    "        '''\n",
    "\n",
    "        # Ejecutar la consulta con el parámetro parametro\n",
    "        cursor.execute(tu_query_sql)\n",
    "\n",
    "        # Obtener los resultados en un DataFrame de pandas\n",
    "        resultados_df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "        # Cerrar el cursor y la conexión\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        # Devolver el DataFrame con los resultados\n",
    "        return resultados_df\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Error al conectar a la base de datos PostgreSQL:\", e)\n",
    "        return None\n",
    "datos = consultar_postgres_hudbay()\n",
    "nombre_archivo = 'bd_hudbay_pases_3m_v2.parquet'\n",
    "datos.to_parquet(nombre_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bc33feb-0c1e-40f0-b06c-7c988cd1b03a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['tiem_llegada_global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b9ad69b-a043-4bd5-8364-3733adca89e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Listamos que buckets se encuentran en nuestro servicio de MINIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe079493-17c4-4631-a529-91e08d09bd27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "import urllib3\n",
    "\n",
    "\n",
    "# Conectar al servidor de MinIO\n",
    "client = Minio(\n",
    "    \"minio.minio-user.svc.cluster.local:80\",  # IP del servidor MinIO\n",
    "    access_key=\"PTDkCupJb66cl9DwvmlW\",\n",
    "    secret_key=\"AkVxpH7t4og1DK6VIJo8jLrdQTBz9a6ZhzOYYT6n\",\n",
    "    secure=False,  # Cambia a False si no usas HTTPS\n",
    "    http_client=urllib3.PoolManager(cert_reqs='CERT_NONE')  # Ignora la verificación del certificado\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Listar los buckets disponibles\n",
    "    buckets = client.list_buckets()\n",
    "    print(\"Buckets disponibles:\")\n",
    "    for bucket in buckets:\n",
    "        print(f\"- {bucket.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar o listar los buckets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abe7f051-a4ab-4701-849b-b71ec0d95688",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.Enviamos el Dataframe de pandas a MINIO, en formato .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27f5feaf-440a-4651-97d5-8072e5c9bdac",
     "showTitle": false,
     "title": ""
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO  # Clase que permite manejar datos binarios en memoria como si fueran archivos \n",
    "from minio import Minio  # Cliente de Python para interactuar con el servidor MinIO.\n",
    "import urllib3   # Biblioteca para realizar peticiones HTTP\n",
    "\n",
    "\n",
    "# Convertir el DataFrame a un buffer en memoria en formato Parquet\n",
    "parquet_buffer = BytesIO()\n",
    "df.to_parquet(parquet_buffer, index=False)\n",
    "parquet_buffer.seek(0)  # Resetea el puntero del buffer a la posición inicial\n",
    "\n",
    "# Conectar al servidor de MinIO\n",
    "client = Minio(\n",
    "    \"minio.minio-user.svc.cluster.local:80\",  # IP del servidor MinIO (mydomain.com)\n",
    "    access_key=\"z7soYFKCcATzYbTWbH3q\",\n",
    "    secret_key=\"ZCRyIjQozBAt0cJnenK0VGY45fl69NBLyWjwAqdl\",\n",
    "    secure=False,  # Cambia a True si usas HTTPS\n",
    "    http_client=urllib3.PoolManager(cert_reqs='CERT_NONE')  # Ignora la verificación del certificado\n",
    ")\n",
    "\n",
    "# Nombre del bucket y del archivo\n",
    "bucket_name = 'pruebabryanbucket'\n",
    "object_name = 'bd_hubbay_pases_3meses.parquet'  # Nombre del archivo Parquet en el bucket\n",
    "\n",
    "# Subir el archivo Parquet al bucket\n",
    "client.put_object(\n",
    "    bucket_name,\n",
    "    object_name,\n",
    "    data=parquet_buffer,\n",
    "    length=parquet_buffer.getbuffer().nbytes\n",
    ")\n",
    "\n",
    "print(f\"'{object_name}' se subió a '{bucket_name}' en MinIO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b011395e-56c5-4366-90d6-dfffb6a6087e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Leemos archivos parquet de MINIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c2e15df-7ab9-4c5c-9e56-93f195373151",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.1 Opcion 1   Leer 1 archivo en especifico desde el Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "648f2ce3-7aae-48a0-b995-236471069d38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from minio import Minio\n",
    "import urllib3\n",
    "\n",
    "# Conectar al servidor de MinIO\n",
    "client = Minio(\n",
    "    \"minio.minio-user.svc.cluster.local:80\",  # Dirección del servidor MinIO\n",
    "    access_key=\"z7soYFKCcATzYbTWbH3q\",         # Clave de acceso\n",
    "    secret_key=\"ZCRyIjQozBAt0cJnenK0VGY45fl69NBLyWjwAqdl\",  # Clave secreta\n",
    "    secure=False,  # Cambia a True si usas HTTPS\n",
    "    http_client=urllib3.PoolManager(cert_reqs='CERT_NONE')  # Ignora la verificación del certificado\n",
    ")\n",
    "\n",
    "# Nombre del bucket y del archivo\n",
    "bucket_name = 'pruebabryanbucket'\n",
    "object_name = 'bd_hubbay_pases_3meses.parquet'  # Nombre del archivo Parquet que quieres leer\n",
    "\n",
    "# Obtener el archivo Parquet del bucket\n",
    "response = client.get_object(bucket_name, object_name)\n",
    "data = response.read()\n",
    "\n",
    "# Convertir los datos leídos en un DataFrame de Pandas\n",
    "parquet_buffer = BytesIO(data)\n",
    "df = pd.read_parquet(parquet_buffer)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66728f56-bde9-4c0a-92d1-8af60aa2f6fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.2 Opcion 2 Leemos varios archivos parquet de MINIO y los unimos en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce6a3c08-f1e9-46d7-a723-a62eed2f0671",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from minio import Minio\n",
    "import urllib3\n",
    "\n",
    "# Conectar al servidor de MinIO\n",
    "client = Minio(\n",
    "    \"minio.minio-user.svc.cluster.local:80\",  # IP del servidor MinIO\n",
    "    access_key=\"0xJ9SgCXmkU3z704qgv1\",\n",
    "    secret_key=\"CgFth8x4tSU9BN9QWBSrMCncOycsWxiIC8egcBUx\",\n",
    "    secure=False,  # Cambia a True si usas HTTPS\n",
    "    http_client=urllib3.PoolManager(cert_reqs='CERT_NONE')  # Ignora la verificación del certificado\n",
    ")\n",
    "\n",
    "# Nombre del bucket\n",
    "bucket_name = 'hudbayextraccion'\n",
    "\n",
    "# Listar todos los objetos en el bucket\n",
    "objects = client.list_objects(bucket_name)\n",
    "\n",
    "# Lista para almacenar DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Leer cada archivo Parquet y añadirlo a la lista de DataFrames\n",
    "for obj in objects:\n",
    "    if obj.object_name.endswith('.parquet'):\n",
    "        response = client.get_object(bucket_name, obj.object_name)\n",
    "        data = response.read()\n",
    "        parquet_buffer = BytesIO(data)\n",
    "        df = pd.read_parquet(parquet_buffer)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Mostrar el DataFrame combinado\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19ca8410-3277-4308-b43f-300dcd596ad6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_df['tiem_llegada_global'].min(), combined_df['tiem_llegada_global'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "743c4477-a37f-45bc-91da-255dbceeebb8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Enviamos el dataframe Unido al MINIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "151ee4d4-1cd1-414b-b8bd-c3d2a9e1fdbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO  # Clase que permite manejar datos binarios en memoria como si fueran archivos \n",
    "from minio import Minio  # Cliente de Python para interactuar con el servidor MinIO.\n",
    "import urllib3   # Biblioteca para realizar peticiones HTTP\n",
    "\n",
    "\n",
    "# Convertir el DataFrame a un buffer en memoria en formato Parquet\n",
    "parquet_buffer = BytesIO()\n",
    "combined_df.to_parquet(parquet_buffer, index=False)\n",
    "parquet_buffer.seek(0)  # Resetea el puntero del buffer a la posición inicial\n",
    "\n",
    "# Nombre del bucket y del archivo\n",
    "object_name = 'bd_hubbay_pases_all.parquet'  # Nombre del archivo Parquet en el bucket\n",
    "\n",
    "# Subir el archivo Parquet al bucket\n",
    "client.put_object(\n",
    "    bucket_name,\n",
    "    object_name,\n",
    "    data=parquet_buffer,\n",
    "    length=parquet_buffer.getbuffer().nbytes\n",
    ")\n",
    "\n",
    "print(f\"'{object_name}' se subió a '{bucket_name}' en MinIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e4e08e2-f74e-45ca-84b4-8e097aeb6c5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "1.extraccion_data_combustible",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
