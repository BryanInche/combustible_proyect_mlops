{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Machine Learning y Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Algoritmo de LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def escalar_por_variables_especificas(dataframe, variables_a_escalar, medias, desviaciones_estandar):\n",
    "  \"\"\"\n",
    "  Escala solo las variables especificadas en un dataframe de forma independiente.\n",
    "\n",
    "  Args:\n",
    "    dataframe: El dataframe que se va a escalar.\n",
    "    variables_a_escalar: Una lista que contiene los nombres de las variables que se van a escalar.\n",
    "    medias: Un diccionario que contiene la media de cada variable.\n",
    "    desviaciones_estandar: Un diccionario que contiene la desviación estándar de cada variable.\n",
    "\n",
    "  Returns:\n",
    "    El dataframe escalado.\n",
    "  \"\"\"\n",
    "  dataframe_escalado = dataframe.copy()\n",
    "  for columna in dataframe.columns:\n",
    "    if columna in variables_a_escalar:\n",
    "      dataframe_escalado[columna] = (dataframe[columna] - medias[columna]) / desviaciones_estandar[columna]\n",
    "  return dataframe_escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(df, num_pasos_futuro=1):  #unistep >> 1 paso al futuro\n",
    "    # Crear un lag (retroceso) de 1 en la columna 'Fuel Consumption Rate(t)'\n",
    "    #df['Fuel Consumption Rate(lag1)'] = df['Fuel Consumption Rate'].shift(1)  # Un lag hacia atrás\n",
    "\n",
    "    # Crear pasos hacia adelante según el número de pasos futuros deseado\n",
    "    for i in range(1, num_pasos_futuro + 1):\n",
    "        df[f'Fuel Consumption Rate(t+{i})'] = df['Fuel Consumption Rate'].shift(-i)  # Shift hacia adelante\n",
    "\n",
    "    # Eliminar filas con NaN en las nuevas columnas de pasos futuros\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para generar las particiones, siguiendo la secuencia de las series temporales\n",
    "def train_val_test_split(serie, tr_size =0.8, vl_size=0.1, ts_size=0.1):\n",
    "    # Definir nunmero de datos en cada subserie\n",
    "    N = serie.shape[0]   #Serie seria el df, con las columnas que intervendran en el Modelo\n",
    "    Ntrain = int(tr_size*N)  # Numero de datos de entrenamiento\n",
    "    Nval = int(vl_size*N)\n",
    "    Ntest = int(ts_size*N)\n",
    "\n",
    "    #Realizar la particion\n",
    "    train = serie[0:Ntrain]\n",
    "    val = serie[Ntrain:Nval+Ntrain]\n",
    "    test = serie[Nval+Ntrain:]\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En Multivariado, poner la variable a predecir, en la columna final\n",
    "c_variables_lstm = ['Intake Manifold #2 Pressure',\n",
    "    # 'Air Filter #3 Restriction',\n",
    "    # 'Air Filter #2 Restriction ',\n",
    "    # 'Air Filter #1 Restriction ',\n",
    "    # 'Air Filter #4 Restriction ',\n",
    "    # 'Percent Fuel Position',\n",
    "    'Roll',\n",
    "    #'Engine Speed','Left Rear Parking Brake Oil Pressure',\n",
    "    'Pitch','Fuel Consumption Rate']\n",
    "\n",
    "\n",
    "datos_df_lstm = datos[c_variables_lstm]  # Modelo Multivariado\n",
    "datos_df_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar todas las columnas excepto la variable objetivo\n",
    "datos_x_escalar_lstm = datos_df_lstm.drop(columns=['Fuel Consumption Rate'])\n",
    "\n",
    "variables_a_escalar_lstm = datos_x_escalar_lstm.columns\n",
    "\n",
    "# Calcular medias y desviaciones estándar para todas las variables\n",
    "medias_lstm = datos_x_escalar_lstm.mean()\n",
    "desviaciones_estandar_lstm = datos_x_escalar_lstm.std()\n",
    "\n",
    "# Escalar solo las variables especificadas en el dataframe train\n",
    "df_escalado_lstm = escalar_por_variables_especificas(datos_x_escalar_lstm, variables_a_escalar_lstm, medias_lstm, desviaciones_estandar_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos el target del data original\n",
    "target_lstm = datos_df_lstm['Fuel Consumption Rate']\n",
    "\n",
    "#Agregamos la target a nuestro datos escalados previamente\n",
    "df_escalado_lstm['Fuel Consumption Rate'] = target_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_escalado_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#4.1 Eliminando columnas especificas que no aportan informacion ( # errors='ignore':ignore cualquier error si alguna de las columnas especificadas no se encuentra en el DataFrame.)\n",
    "# datos_escalados_lstm = datos_escalados_lstm.drop(['Fuel Consumption Rate(lag1)'], axis=1, errors='ignore')\n",
    "\n",
    "datos_escalados_lstm = df_escalado_lstm.copy()\n",
    "\n",
    "# Verifica el resultado\n",
    "# Llamar a la función para agregar el lag y obtener el nuevo DataFrame\n",
    "datos_escalados_lstm = add_lags(datos_escalados_lstm)\n",
    "datos_escalados_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Renombrar las columnas del df\n",
    "# Renombrar columnas específicas\n",
    "\n",
    "datos_escalados_lstm = datos_escalados_lstm.rename(columns={\n",
    "    'Fuel Consumption Rate': 'Fuel Consumption Rate(lag1)',\n",
    "    'Fuel Consumption Rate(t+1)': 'Fuel Consumption Rate(target)'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_escalados_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de características (features) que usaremos para X\n",
    "FEATURES = datos_escalados_lstm.columns.drop('Fuel Consumption Rate(target)')\n",
    "\n",
    "# Columna objetivo\n",
    "TARGET = 'Fuel Consumption Rate(target)'\n",
    "\n",
    "# Particionar los datos en entrenamiento, validación y prueba\n",
    "train_lstm, val_lstm, test_lstm = train_val_test_split(datos_escalados_lstm)\n",
    "\n",
    "# Separar las características (X) y la etiqueta (y) en cada partición\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "X_train_lstm = train_lstm[FEATURES]\n",
    "y_train_lstm = train_lstm[TARGET]\n",
    "\n",
    "# Conjunto de validación\n",
    "X_val_lstm = val_lstm[FEATURES]\n",
    "y_val_lstm = val_lstm[TARGET]\n",
    "\n",
    "# Conjunto de prueba\n",
    "X_test_lstm = test_lstm[FEATURES]\n",
    "y_test_lstm = test_lstm[TARGET]\n",
    "\n",
    "# Visualizar los tamaños de los conjuntos\n",
    "print(f\"Tamaño de X_train: {X_train_lstm.shape}, y_train: {y_train_lstm.shape}\")\n",
    "print(f\"Tamaño de X_val: {X_val_lstm.shape}, y_val: {y_val_lstm.shape}\")\n",
    "print(f\"Tamaño de X_test: {X_test_lstm.shape}, y_test: {y_test_lstm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Definir el número de timesteps\n",
    "timesteps = 2  # Ajusta según tus necesidades\n",
    "\n",
    "# Función para crear secuencias\n",
    "def create_sequences(data_x, data_y, timesteps):\n",
    "    X, y, indices = [], [], []\n",
    "    for i in range(len(data_x) - timesteps):\n",
    "        X.append(data_x.iloc[i:i+timesteps].values)\n",
    "        y.append(data_y.iloc[i + timesteps])\n",
    "        indices.append(data_y.index[i + timesteps])  # Guardar el índice correspondiente\n",
    "    return np.array(X), np.array(y), indices\n",
    "\n",
    "# Crear las secuencias para el conjunto de entrenamiento\n",
    "X_train_seq_lstm, y_train_seq_lstm, train_indices = create_sequences(X_train_lstm, y_train_lstm, timesteps)\n",
    "\n",
    "# Crear las secuencias para el conjunto de validación\n",
    "X_val_seq_lstm, y_val_seq_lstm, val_indices = create_sequences(X_val_lstm, y_val_lstm, timesteps)\n",
    "\n",
    "# Crear las secuencias para el conjunto de prueba\n",
    "X_test_seq_lstm, y_test_seq_lstm, test_indices = create_sequences(X_test_lstm, y_test_lstm, timesteps)\n",
    "\n",
    "# Imprimir tamaños para confirmar\n",
    "print(f\"Tamaño de X_train_seq: {X_train_seq_lstm.shape}, y_train_seq: {y_train_seq_lstm.shape}\")\n",
    "print(f\"Tamaño de X_val_seq: {X_val_seq_lstm.shape}, y_val_seq: {y_val_seq_lstm.shape}\")\n",
    "print(f\"Tamaño de X_test_seq: {X_test_seq_lstm.shape}, y_test_seq: {y_test_seq_lstm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_seq_lstm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_seq_lstm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fijar valores de los parámetros para asegurar la reproducibilidad\n",
    "tf.random.set_seed(123)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Definir el modelo\n",
    "N_UNITS = 50  # Tamaño del estado oculto de la celda de Memoria de LSTM\n",
    "INPUT_SHAPE = (X_train_seq_lstm.shape[1], X_train_seq_lstm.shape[2])  # (timesteps)pasos atrás x n features\n",
    "\n",
    "modelo_lstm = Sequential()\n",
    "modelo_lstm.add(LSTM(N_UNITS, input_shape=INPUT_SHAPE))\n",
    "modelo_lstm.add(Dense(1, activation='linear'))  # Predicción de un solo paso futuro\n",
    "\n",
    "# Compilar el modelo para un problema de regresión\n",
    "modelo_lstm.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Ajuste a regresión\n",
    "\n",
    "# Entrenar el modelo\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "historia = modelo_lstm.fit(\n",
    "    x = X_train_seq_lstm,\n",
    "    y = y_train_seq_lstm,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = (X_val_seq_lstm, y_val_seq_lstm),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los resultados\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(historia.history['loss'], label='train')\n",
    "plt.plot(historia.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Obtener las predicciones para el conjunto de prueba\n",
    "y_pred_lstm = modelo_lstm.predict(X_test_seq_lstm)\n",
    "\n",
    "# Crear una serie de pandas para las predicciones con el índice correspondiente\n",
    "y_pred_series = pd.Series(y_pred_lstm.flatten(), index=test_indices)\n",
    "\n",
    "# Crear el gráfico con Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Añadir la serie de valores reales\n",
    "fig.add_trace(go.Scatter(x=test_indices, y=y_test_seq_lstm, mode='lines', name='Valores Reales', line=dict(color='blue')))\n",
    "\n",
    "# Añadir la serie de valores predichos\n",
    "fig.add_trace(go.Scatter(x=y_pred_series.index, y=y_pred_series, mode='lines', name='Valores Predichos', line=dict(color='green')))\n",
    "\n",
    "# Personalizar el gráfico\n",
    "fig.update_layout(\n",
    "    title='Serie Temporal: Valores Reales vs Predichos',\n",
    "    xaxis_title='Fecha',\n",
    "    yaxis_title='Consumo Combustible (Ltrs/hora)',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
